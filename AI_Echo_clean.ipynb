{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgFC_hwHuafp"
   },
   "source": [
    "# PROJECT TITLE - AI Echo: Your Smartest Conversational Partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUUL-hST-yMA"
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1. Import Libraries\n",
    "# ================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "9NkzsGEn_R7K",
    "outputId": "763ae336-83d1-4737-d002-e205fa18cc79"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/chatgpt_style_reviews_dataset.csv\")   # your dataset file\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1Jk2rfJ_cJt",
    "outputId": "e6bf5f28-2626-4fef-ef6a-652c123317d0"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOGpVAOK_lg1",
    "outputId": "8f86e086-8c7f-4915-8f96-ce57687decbb"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "Ws2R39C0A40F",
    "outputId": "02cbf81b-329d-4d9b-c9ee-a00454d1a530"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9swfUKiiuPdr"
   },
   "source": [
    "### Data preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "bSj_hFIRA4qI",
    "outputId": "ced2fbd7-d603-4cd4-c171-5ce1525f4daf"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bKVMArFKA4my",
    "outputId": "b36a6e3e-3000-4b03-87fc-c9875be290f6"
   },
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhvwyS-O_n9S",
    "outputId": "90eb6b3d-fc65-4065-a0d4-a43c3583b9e7"
   },
   "outputs": [],
   "source": [
    "# Handle Missing Values\n",
    "\n",
    "# Drop rows with missing reviews or ratings\n",
    "df = df.dropna(subset=[\"review\", \"rating\"])\n",
    "\n",
    "# Fill other missing values if needed\n",
    "df = df.fillna({\"title\": \"\", \"username\": \"unknown\", \"location\": \"unknown\"})\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "-KIeJzux_9Nz",
    "outputId": "1436985a-5d74-4ea9-cae5-0e138feaa7e7"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xmRJIN5IVg9T",
    "outputId": "68192758-81f2-4eeb-f41d-a50266930790"
   },
   "outputs": [],
   "source": [
    "df[\"username\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "wnRYbX-GVon0",
    "outputId": "15585803-b185-428a-da93-1f2a548655ff"
   },
   "outputs": [],
   "source": [
    "df[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "q5aYLm8kV156",
    "outputId": "640bf5f5-89ac-4f9b-b308-071ca0e35539"
   },
   "outputs": [],
   "source": [
    "df[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "rzYEsekvWAqw",
    "outputId": "95783401-a580-470a-ac7a-985b147af679"
   },
   "outputs": [],
   "source": [
    "df[\"platform\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ygtdk_PM9nZx",
    "outputId": "78e046f9-c44f-4843-bac2-db9c8fb2f110"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)          # remove URLs\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)               # remove punctuation/special chars\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()            # normalize spaces\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in text.split() if w not in stop_words]\n",
    "    return \" \".join(tokens) if tokens else \"neutral\"\n",
    "\n",
    "df[\"cleaned_review\"] = df[\"review\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IWrVlHy9nWY"
   },
   "outputs": [],
   "source": [
    "def label_sentiment(r):\n",
    "    if r >= 4: return \"Positive\"\n",
    "    elif r == 3: return \"Neutral\"\n",
    "    else: return \"Negative\"\n",
    "\n",
    "df[\"sentiment\"] = df[\"rating\"].apply(label_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "gc5gsYDAy3L8",
    "outputId": "5d19a648-e1e3-4148-dadc-e52a6971bb39"
   },
   "outputs": [],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "EER5AhfSv6_c",
    "outputId": "52d8b9d4-38b1-4aa1-8c58-8e251387481b"
   },
   "outputs": [],
   "source": [
    "# Sentiment Distribution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"sentiment\"].value_counts().plot(kind=\"bar\", color=[\"red\",\"blue\",\"green\"])\n",
    "plt.title(\"Sentiment Distribution\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "nDCm1T6wv68S",
    "outputId": "904dc53c-848c-4e5a-da2f-d16470b4c60e"
   },
   "outputs": [],
   "source": [
    "# WordCloud of Reviews\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "text = \" \".join(df[\"cleaned_review\"].astype(str))\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud of Reviews\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "WguHCKPqwVEc",
    "outputId": "6c868645-8ecf-465f-9329-468348fc9ba2"
   },
   "outputs": [],
   "source": [
    "# Histogram of Review Lengths\n",
    "\n",
    "plt.hist(df[\"review_length\"], bins=10, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Histogram of Review Lengths\")\n",
    "plt.xlabel(\"Review Length (words)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "wMJFoifB3i2U",
    "outputId": "115d6d19-e383-4c58-e0df-41a6af1233a0"
   },
   "outputs": [],
   "source": [
    "#ðŸ“Š 1. What is the distribution of review ratings?\n",
    "#Visualization: Bar Chart for ratings (1â€“5 stars)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['rating'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.xlabel(\"Rating (1â€“5 stars)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Review Ratings\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYDpIxWn3PXy"
   },
   "source": [
    "Insight:\n",
    "\n",
    "This shows whether the overall sentiment trends positive or negative.\n",
    "\n",
    "If 4â€“5 stars dominate â†’ customers are happy.\n",
    "\n",
    "If 1â€“2 stars dominate â†’ major dissatisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 947
    },
    "id": "pLO5UJkO3uij",
    "outputId": "5fe1a5b8-2962-469e-d4c4-d6235ad3944e"
   },
   "outputs": [],
   "source": [
    "# ðŸ‘ðŸ‘Ž 2. How many reviews were marked as helpful?\n",
    "# Define â€œhelpfulâ€ as reviews with helpful_votes >= 10.\n",
    "# Visualization: Bar Chart or Pie Chart (Helpful vs. Not Helpful)\n",
    "\n",
    "df['is_helpful'] = df['helpful_votes'] >= 10\n",
    "df['is_helpful'].value_counts().plot(kind='bar')\n",
    "plt.xticks([0,1], [\"Not Helpful\", \"Helpful\"])\n",
    "plt.title(\"Helpful Review Distribution\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create helpful flag\n",
    "df[\"helpful_flag\"] = df[\"helpful_votes\"].apply(lambda x: \"Helpful\" if x > 10 else \"Not Helpful\")\n",
    "\n",
    "# Pie chart of helpful vs not helpful\n",
    "df[\"helpful_flag\"].value_counts().plot(kind=\"pie\", autopct=\"%1.1f%%\", colors=[\"green\",\"red\"])\n",
    "plt.title(\"Helpful vs Not Helpful Reviews (Threshold >10)\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "G8AB2gtv4uUD",
    "outputId": "fbf0134a-2db0-4425-ee91-eb19397f9a75"
   },
   "outputs": [],
   "source": [
    "# 3. What are the most common keywords in positive vs. negative reviews?\n",
    "# Split by sentiment or rating.\n",
    "# Visualization: Two Word Clouds--- Positive (4â€“5 stars), Negative (1â€“2 stars)\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Positive reviews (ratings 4â€“5)\n",
    "positive_text = \" \".join(df[df[\"rating\"] >= 4][\"cleaned_review\"].astype(str))\n",
    "wordcloud_pos = WordCloud(width=800, height=400, background_color=\"white\").generate(positive_text)\n",
    "\n",
    "# Negative reviews (ratings 1â€“2)\n",
    "negative_text = \" \".join(df[df[\"rating\"] <= 2][\"cleaned_review\"].astype(str))\n",
    "wordcloud_neg = WordCloud(width=800, height=400, background_color=\"white\").generate(negative_text)\n",
    "\n",
    "# Plot side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "axes[0].imshow(wordcloud_pos, interpolation=\"bilinear\")\n",
    "axes[0].set_title(\"Positive Reviews (4â€“5 Stars)\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(wordcloud_neg, interpolation=\"bilinear\")\n",
    "axes[1].set_title(\"Negative Reviews (1â€“2 Stars)\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "qZdoPeDxw0Gr",
    "outputId": "bac2b830-824e-4e55-87b2-cba705d3b05b"
   },
   "outputs": [],
   "source": [
    "# 4. How has the average rating changed over time?\n",
    "# Visualization: Line chart:\n",
    "# X-axis â†’ date\n",
    "# Y-axis â†’ average rating\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure 'date' column is in datetime format\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Group by date and calculate average rating\n",
    "avg_rating = df.groupby(\"date\")[\"rating\"].mean()\n",
    "\n",
    "# Plot line chart\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(avg_rating.index, avg_rating.values, marker=\"o\", linestyle=\"-\", color=\"blue\")\n",
    "plt.title(\"Average Rating Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Rating\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "id": "UgWZzKZ76E-q",
    "outputId": "e72392c7-a478-41ff-efba-9764c2b17261"
   },
   "outputs": [],
   "source": [
    "# 5. How do ratings vary by user location?\n",
    "# Visualization: Bar chart of average rating per location\n",
    "# (If you want advanced: world map using plotly geo)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate average rating per location\n",
    "avg_rating_location = df.groupby(\"location\")[\"rating\"].mean().sort_values()\n",
    "\n",
    "# Plot bar chart\n",
    "plt.figure(figsize=(12,6))\n",
    "avg_rating_location.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Average Rating by User Location\")\n",
    "plt.xlabel(\"Location\")\n",
    "plt.ylabel(\"Average Rating\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "it9f4h_X7co-",
    "outputId": "8f5c39c4-7a07-4354-b3fa-19c89e649415"
   },
   "outputs": [],
   "source": [
    "# âœ… 6. Which platform (Web vs Mobile) gets better reviews?\n",
    "# Grouped Bar Chart â€” Average Rating by Platform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "platform_avg = df.groupby(\"platform\")[\"rating\"].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(platform_avg[\"platform\"], platform_avg[\"rating\"])\n",
    "plt.title(\"Average Rating by Platform  (Web vs Mobile)\")\n",
    "plt.xlabel(\"Platform\")\n",
    "plt.ylabel(\"Average Rating\")\n",
    "plt.ylim(0, 5)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "# Add values on bars\n",
    "for i, val in enumerate(platform_avg[\"rating\"]):\n",
    "    plt.text(i, val + 0.05, f\"{val:.2f}\", ha='center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "ngJVJQRs8BoU",
    "outputId": "669ef642-2df6-4ae3-cc14-527e03ab27d4"
   },
   "outputs": [],
   "source": [
    "# âœ… 7. Are verified users more satisfied than non-verified ones?\n",
    "# Side-by-Side Bar Chart: Verified vs. Non-Verified\n",
    "\n",
    "verified_avg = df.groupby(\"verified_purchase\")[\"rating\"].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(verified_avg[\"verified_purchase\"], verified_avg[\"rating\"], color=['skyblue','orange'])\n",
    "plt.title(\"Average Rating: Verified vs Non-Verified Users\")\n",
    "plt.xlabel(\"User Type\")\n",
    "plt.ylabel(\"Average Rating\")\n",
    "plt.ylim(0, 5)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "for i, val in enumerate(verified_avg[\"rating\"]):\n",
    "    plt.text(i, val + 0.05, f\"{val:.2f}\", ha='center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "8tTFI6tX6E25",
    "outputId": "4afa8c6a-13eb-4610-c576-f76b3649ee7c"
   },
   "outputs": [],
   "source": [
    "# 8. Average length of reviews per rating\n",
    "# Bar Chart: Review Length by Rating\n",
    "\n",
    "rating_avg_len = df.groupby(\"rating\")[\"review_length\"].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(rating_avg_len[\"rating\"], rating_avg_len[\"review_length\"], color=\"purple\")\n",
    "plt.title(\"Average Review Length by Rating\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Average Review Length (characters)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "# Set y-limit 20% higher than max value\n",
    "plt.ylim(0, rating_avg_len[\"review_length\"].max() * 1.2)\n",
    "\n",
    "for i, val in enumerate(rating_avg_len[\"review_length\"]):\n",
    "    plt.text(rating_avg_len[\"rating\"][i], val + 2, f\"{val:.1f}\", ha='center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 948
    },
    "id": "fnzW9uVo88OQ",
    "outputId": "ad3009fb-9454-42dd-fdb6-ec0bb68e142d"
   },
   "outputs": [],
   "source": [
    "# 9. Most mentioned words in 1-star reviews\n",
    "# Word Cloud\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Filter 1-star reviews\n",
    "one_star_reviews = df[df[\"rating\"] == 1][\"cleaned_review\"]\n",
    "\n",
    "# Word Cloud\n",
    "text = \" \".join(one_star_reviews.astype(str))\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud of 1-Star Reviews\")\n",
    "plt.show()\n",
    "\n",
    "# Bar Chart of Top 10 Words\n",
    "words = text.split()\n",
    "word_counts = Counter(words)\n",
    "common_words = word_counts.most_common(10)\n",
    "\n",
    "plt.bar([w for w, _ in common_words], [c for _, c in common_words], color=\"red\")\n",
    "plt.title(\"Top 10 Words in 1-Star Reviews\")\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "u58wtNRW-TKJ",
    "outputId": "7af55b16-9c7e-4204-a3cd-06eaec33d423"
   },
   "outputs": [],
   "source": [
    "#10. Which ChatGPT version gets the highest rating?\n",
    "#Bar Chart: Version vs Average Rating\n",
    "\n",
    "# Group by version and calculate average rating\n",
    "avg_rating_version = df.groupby(\"version\")[\"rating\"].mean().sort_values()\n",
    "\n",
    "# Bar chart\n",
    "plt.figure(figsize=(10,6))\n",
    "avg_rating_version.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Average Rating by ChatGPT Version\")\n",
    "plt.xlabel(\"Version\")\n",
    "plt.ylabel(\"Average Rating\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylim(0,5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "6ELKDxtNeaod",
    "outputId": "92e9553d-71b0-4579-af05-9f187c6ac44e"
   },
   "outputs": [],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6aaDYbR3jZ7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwCqIsRe3h8U"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df.sentiment==\"Negative\"]\n",
    "df_minority_pos = df[df.sentiment==\"Positive\"]\n",
    "df_minority_neu = df[df.sentiment==\"Neutral\"]\n",
    "\n",
    "df_pos_upsampled = resample(df_minority_pos, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "df_neu_upsampled = resample(df_minority_neu, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([df_majority, df_pos_upsampled, df_neu_upsampled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7GnLoUUNet-B",
    "outputId": "87a581c1-0753-4c72-e783-6ed236b6c3a7"
   },
   "outputs": [],
   "source": [
    "print(df[[\"cleaned_review\", \"sentiment\"]].head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6Q6ec5KkbI0"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"/content/chatgpt_style_reviews_dataset_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "c0P3PemNka7e",
    "outputId": "f26c37d7-7fa6-43ff-b8cd-90a3f4662ee1"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"/content/chatgpt_style_reviews_dataset_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "EdFfAGU-e9f6",
    "outputId": "3cff926a-c4c7-4d14-f477-8ff142a12c91"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/chatgpt_style_reviews_dataset_cleaned.csv\")   # your dataset file\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAGlJZkze9ce"
   },
   "outputs": [],
   "source": [
    "# Handle Missing Values\n",
    "\n",
    "# Drop rows with missing reviews or ratings\n",
    "df = df.dropna(subset=[\"review\", \"rating\"])\n",
    "\n",
    "# Fill other missing values if needed\n",
    "df = df.fillna({\"title\": \"\", \"username\": \"unknown\", \"location\": \"unknown\"})\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6TWpWl0pe9ZN",
    "outputId": "6ddb1489-ca13-4965-e845-e0598fb3d55d"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgk2CVCewMqe"
   },
   "source": [
    "### Sentiment Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHXtH6djte5-"
   },
   "source": [
    "#### TF-IDF vectorization and Train Logistic Regression, Naive Bayes, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1U0GBAuWUR2",
    "outputId": "dd2cfa7d-224c-48ce-996b-e7e230da2582"
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 0. INSTALLS (ONLY FOR COLAB)\n",
    "# ======================================================\n",
    "!pip install langdetect nltk scikit-learn pandas joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import joblib\n",
    "\n",
    "from langdetect import detect, DetectorFactory\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "DetectorFactory.seed = 0\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\")) - {\"no\", \"nor\", \"not\"}\n",
    "\n",
    "# ======================================================\n",
    "# 1. CLEANING FUNCTIONS\n",
    "# ======================================================\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text): return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    tokens = [w for w in text.split() if w not in stop_words]\n",
    "    return \" \".join(tokens) if tokens else \"neutral\"\n",
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def label_sentiment(r):\n",
    "    r = int(r)\n",
    "    if r >= 4: return \"Positive\"\n",
    "    elif r == 3: return \"Neutral\"\n",
    "    else: return \"Negative\"\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 2. LOAD + CLEAN DATA\n",
    "# ======================================================\n",
    "df = pd.read_csv(\"/content/chatgpt_style_reviews_dataset.csv\")\n",
    "\n",
    "df = df.dropna(subset=[\"review\", \"rating\"])\n",
    "df = df[df[\"review\"].apply(is_english)]\n",
    "\n",
    "df[\"cleaned\"] = df[\"review\"].apply(clean_text)\n",
    "df[\"sentiment\"] = df[\"rating\"].apply(label_sentiment)\n",
    "\n",
    "df = df[[\"cleaned\", \"sentiment\"]]\n",
    "\n",
    "print(\"\\nOriginal distribution:\\n\", df[\"sentiment\"].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 3. BALANCE CLASSES (UPSAMPLING)\n",
    "# ======================================================\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_neg = df[df.sentiment == \"Negative\"]\n",
    "df_pos = df[df.sentiment == \"Positive\"]\n",
    "df_neu = df[df.sentiment == \"Neutral\"]\n",
    "\n",
    "max_count = max(len(df_neg), len(df_pos), len(df_neu))\n",
    "\n",
    "df_neg_up = resample(df_neg, replace=True, n_samples=max_count, random_state=42)\n",
    "df_pos_up = resample(df_pos, replace=True, n_samples=max_count, random_state=42)\n",
    "df_neu_up = resample(df_neu, replace=True, n_samples=max_count, random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([df_neg_up, df_pos_up, df_neu_up]).sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"\\nBalanced distribution:\\n\", df_balanced[\"sentiment\"].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 4. TF-IDF VECTORISATION\n",
    "# ======================================================\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_text = df_balanced[\"cleaned\"]\n",
    "y = df_balanced[\"sentiment\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(X_text)\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 5. TRAIN / TEST SPLIT\n",
    "# ======================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 6. DEFINE & TRAIN MODELS\n",
    "# ======================================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
    "    \"NaÃ¯ve Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 7. EVALUATION\n",
    "# ======================================================\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, classification_report\n",
    "\n",
    "def evaluate(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred, average=\"macro\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n====== {model_name} ======\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # AUC only for models that support predict_proba\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)\n",
    "        y_test_bin = pd.get_dummies(y_test)\n",
    "        print(\"AUC-ROC:\", roc_auc_score(y_test_bin, y_prob, multi_class=\"ovr\"))\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    evaluate(model, X_test, y_test, name)\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 8. SAVE MODELS + VECTORIZER\n",
    "# ======================================================\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "joblib.dump(models[\"Random Forest\"], \"sentiment_random_forest.pkl\")\n",
    "joblib.dump(models[\"Logistic Regression\"], \"sentiment_logreg.pkl\")\n",
    "joblib.dump(models[\"NaÃ¯ve Bayes\"], \"sentiment_nb.pkl\")\n",
    "\n",
    "print(\"\\nModels saved successfully!\")\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 9. LOAD & PREDICT FROM SAVED MODEL\n",
    "# ======================================================\n",
    "def load_and_predict(text):\n",
    "    vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "    model = joblib.load(\"sentiment_random_forest.pkl\")   # choose best model\n",
    "\n",
    "    cleaned = clean_text(text)\n",
    "    X_vec = vectorizer.transform([cleaned])\n",
    "    pred = model.predict(X_vec)[0]\n",
    "    return pred\n",
    "\n",
    "\n",
    "# Test predictions\n",
    "samples = [\n",
    "     \"Customer support was okay, nothing special.\",\n",
    "    \"Amazing experience! Fast delivery and great product.\",\n",
    "    \"Terrible quality, would not recommend.\"\n",
    "]\n",
    "\n",
    "print(\"\\nSAMPLE PREDICTIONS:\")\n",
    "for s in samples:\n",
    "    print(s, \"â†’\", load_and_predict(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eBQSxagun2T"
   },
   "source": [
    "#### Sentence-BERT embedding generation and Train ML models (LogReg, RandomForest) on embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "17bf4f4902014d6f82b843b2d768e2a0",
      "b80392e46a8e4c1a8c4d1b35af37ef55",
      "656cf2efac1746ce9ad43a31ba92e13a",
      "8254aff29a5941e4afe5c03c40359910",
      "84c5ba7e79ec45bea2e98d110a5870b5",
      "27de81ab823e423db2161728dc726504",
      "38fbdaef740c443b9d0e44b5cd7a28dc",
      "a9c9ca43fac449eba54ee281dbc04071",
      "aa98452321724fb893233a40ac3545ac",
      "29b93cec6b8a4b7db9a78520b65210de",
      "3fc068577d2347de92cb17d8a3d6e20e"
     ]
    },
    "id": "YGyP9rnkuRrF",
    "outputId": "358bba31-d820-47e6-e098-b69976159ecf"
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 0. INSTALLS (Colab)\n",
    "# ======================================================\n",
    "!pip install -q sentence-transformers langdetect nltk scikit-learn joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import joblib\n",
    "from langdetect import detect, DetectorFactory\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "DetectorFactory.seed = 0\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\")) - {\"no\", \"nor\", \"not\"}\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 1. CLEANING FUNCTIONS\n",
    "# ======================================================\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text): return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    tokens = [w for w in text.split() if w not in stop_words]\n",
    "    return \" \".join(tokens) if tokens else \"neutral\"\n",
    "\n",
    "def is_english(text):\n",
    "    try: return detect(text) == \"en\"\n",
    "    except: return False\n",
    "\n",
    "def label_sentiment(r):\n",
    "    r = int(r)\n",
    "    if r >= 4: return \"Positive\"\n",
    "    elif r == 3: return \"Neutral\"\n",
    "    else: return \"Negative\"\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 2. LOAD + CLEAN DATA\n",
    "# ======================================================\n",
    "df = pd.read_csv(\"/content/chatgpt_style_reviews_dataset.csv\")\n",
    "\n",
    "df = df.dropna(subset=[\"review\", \"rating\"])\n",
    "df = df[df[\"review\"].apply(is_english)]\n",
    "\n",
    "df[\"cleaned\"] = df[\"review\"].apply(clean_text)\n",
    "df[\"sentiment\"] = df[\"rating\"].apply(label_sentiment)\n",
    "\n",
    "df = df[[\"cleaned\", \"sentiment\"]]\n",
    "\n",
    "print(\"\\nOriginal distribution:\\n\", df[\"sentiment\"].value_counts())\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 3. BALANCE CLASSES (UPSAMPLING)\n",
    "# ======================================================\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_neg = df[df.sentiment == \"Negative\"]\n",
    "df_pos = df[df.sentiment == \"Positive\"]\n",
    "df_neu = df[df.sentiment == \"Neutral\"]\n",
    "\n",
    "max_count = max(len(df_neg), len(df_pos), len(df_neu))\n",
    "\n",
    "df_neg_up = resample(df_neg, replace=True, n_samples=max_count, random_state=42)\n",
    "df_pos_up = resample(df_pos, replace=True, n_samples=max_count, random_state=42)\n",
    "df_neu_up = resample(df_neu, replace=True, n_samples=max_count, random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([df_neg_up, df_pos_up, df_neu_up]).sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"\\nBalanced distribution:\\n\", df_balanced[\"sentiment\"].value_counts())\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 4. SENTENCE-BERT: EMBEDDING GENERATION\n",
    "# ======================================================\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"\\nLoading Sentence-BERT model...\")\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "X_text = df_balanced[\"cleaned\"].tolist()\n",
    "y = df_balanced[\"sentiment\"].tolist()\n",
    "\n",
    "print(\"Generating embeddings...\")\n",
    "X_embeddings = sbert_model.encode(X_text, batch_size=64, show_progress_bar=True)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 5. TRAIN/TEST SPLIT\n",
    "# ======================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_embeddings, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 6. DEFINE & TRAIN MODELS\n",
    "# ======================================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 7. EVALUATION\n",
    "# ======================================================\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred, average=\"macro\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n====== {model_name} ======\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)\n",
    "        y_test_bin = pd.get_dummies(y_test)\n",
    "        print(\"AUC-ROC:\", roc_auc_score(y_test_bin, y_prob, multi_class=\"ovr\"))\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    evaluate(model, X_test, y_test, name)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 8. SAVE MODELS + SBERT\n",
    "# ======================================================\n",
    "joblib.dump(models[\"Logistic Regression\"], \"sentiment_logreg_sbert.pkl\")\n",
    "joblib.dump(models[\"Random Forest\"], \"sentiment_rf_sbert.pkl\")\n",
    "joblib.dump(sbert_model, \"sbert_model.pkl\")\n",
    "\n",
    "print(\"\\nModels saved successfully!\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 9. LOAD & PREDICT\n",
    "# ======================================================\n",
    "def load_and_predict(text):\n",
    "    sbert = joblib.load(\"sbert_model.pkl\")\n",
    "    model = joblib.load(\"sentiment_rf_sbert.pkl\")  # choose best model\n",
    "\n",
    "    cleaned = clean_text(text)\n",
    "    emb = sbert.encode([cleaned])\n",
    "    pred = model.predict(emb)[0]\n",
    "    return pred\n",
    "\n",
    "\n",
    "# Sample Predictions\n",
    "samples = [\n",
    "     \"Customer support was okay, nothing special.\",\n",
    "    \"Amazing experience! Fast delivery and great product.\",\n",
    "    \"Terrible quality, would not recommend.\"\n",
    "]\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "for s in samples:\n",
    "    print(s, \"â†’\", load_and_predict(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhMPAPhNwNXv"
   },
   "source": [
    "#### BERT fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489,
     "referenced_widgets": [
      "dae2d2b579fa424d8a7dfb2aba583b00",
      "6168b7d5086f45ec8b97098d8c996db1",
      "827bec617723437799184f13dbe0c436",
      "99d548631bf447a9afb38dbdc7eee3fe",
      "179743e0505c4ce4960fed08b934de5c",
      "f15588376af24b86bbe817657c83a6aa",
      "c840e68d754b4b3db0c4acf8a90114d7",
      "a4fe33548c58486684dc7756f3ab7949",
      "f7e6e1088939466a89914e496e603f42",
      "19b29bf8f4fe405d99928fc146d76d65",
      "fe0f850a2f8841459bb3093cde483696",
      "5621abb68d2d41fa87591b6619a99d10",
      "c487d0d73516425ca796aff3da93a5f8",
      "5c115e418ccf402ba9dd71bde6253b42",
      "8abac191fbe94752a8451277682b43b0",
      "a8c81171dd124fc6a3dd67abc2c7a684",
      "3e6af79d0151420191a6600939758b18",
      "3cc9f1141ede4b3fb61fd011be77f346",
      "a010830bb2444477bc3d4ed132699da8",
      "9d2c94f9253b4ce5b381ff446e7d8a14",
      "90986c630a2a469c92b48f6dbc60a82a",
      "5e7e8c8202264e9dafb19a5389631dce"
     ]
    },
    "id": "OIP0kmNFwPoy",
    "outputId": "c80a3030-d9a8-42ee-e4a5-f35ca3801299"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. INSTALL DEPENDENCIES\n",
    "# ============================================================\n",
    "!pip install transformers datasets accelerate sentencepiece -q\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. IMPORTS\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    BertTokenizerFast,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. TEXT CLEANING FUNCTION\n",
    "# ============================================================\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. SIMPLE ENGLISH FILTER (ASCII BASED)\n",
    "# ============================================================\n",
    "def is_english(text, threshold=0.7):\n",
    "    text = str(text)\n",
    "    if len(text) == 0:\n",
    "        return False\n",
    "    english_chars = sum(c.isascii() for c in text)\n",
    "    return english_chars / len(text) >= threshold\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. LOAD DATA + CLEAN + FILTER\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"/content/chatgpt_style_reviews_dataset.csv\")\n",
    "\n",
    "df[\"cleaned\"] = df[\"review\"].apply(clean_text)\n",
    "df = df[df[\"cleaned\"].apply(is_english)]\n",
    "\n",
    "print(\"Rows after English filtering:\", len(df))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. LABEL SENTIMENT USING RATING\n",
    "# ============================================================\n",
    "def label_sentiment(r):\n",
    "    r = int(r)\n",
    "    if r >= 4:\n",
    "        return \"Positive\"\n",
    "    elif r == 3:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "df[\"sentiment\"] = df[\"rating\"].apply(label_sentiment)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. BALANCE CLASSES\n",
    "# ============================================================\n",
    "df_neg = df[df.sentiment == \"Negative\"]\n",
    "df_pos = df[df.sentiment == \"Positive\"]\n",
    "df_neu = df[df.sentiment == \"Neutral\"]\n",
    "\n",
    "max_count = max(len(df_neg), len(df_pos), len(df_neu))\n",
    "\n",
    "df_neg_up = resample(df_neg, replace=True, n_samples=max_count, random_state=42)\n",
    "df_pos_up = resample(df_pos, replace=True, n_samples=max_count, random_state=42)\n",
    "df_neu_up = resample(df_neu, replace=True, n_samples=max_count, random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([df_neg_up, df_pos_up, df_neu_up]).sample(frac=1, random_state=42)\n",
    "\n",
    "df = df_balanced\n",
    "print(\"\\nBalanced counts:\\n\", df.sentiment.value_counts())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. LABEL ENCODING\n",
    "# ============================================================\n",
    "label2id = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "id2label = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "\n",
    "df[\"label\"] = df[\"sentiment\"].map(label2id)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9. TRAIN / TEST SPLIT\n",
    "# ============================================================\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 10. TOKENIZATION\n",
    "# ============================================================\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"cleaned\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "test_ds = test_ds.map(tokenize, batched=True)\n",
    "\n",
    "train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 11. LOAD BERT FOR FINE-TUNING\n",
    "# ============================================================\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 12. TRAINING ARGUMENTS (NO W&B)\n",
    "# ============================================================\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_sentiment\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\"           # <-- IMPORTANT: disables W&B fully\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 13. METRICS\n",
    "# ============================================================\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"macro\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 14. TRAIN\n",
    "# ============================================================\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 15. SAVE MODEL\n",
    "# ============================================================\n",
    "trainer.save_model(\"final_bert_model\")\n",
    "tokenizer.save_pretrained(\"final_bert_model\")\n",
    "\n",
    "print(\"Model saved â†’ final_bert_model/\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 16. LOAD MODEL FOR INFERENCE\n",
    "# ============================================================\n",
    "loaded_model = BertForSequenceClassification.from_pretrained(\"final_bert_model\")\n",
    "loaded_tokenizer = BertTokenizerFast.from_pretrained(\"final_bert_model\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 17. PREDICTION FUNCTION\n",
    "# ============================================================\n",
    "def predict_sentiment(text):\n",
    "    inputs = loaded_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1)\n",
    "        pred = torch.argmax(probs).item()\n",
    "\n",
    "    return id2label[pred], probs.tolist()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 18. SAMPLE PREDICTIONS\n",
    "# ============================================================\n",
    "samples = [\n",
    "    \"The product quality is excellent but delivery was slow.\",\n",
    "    \"I am not happy with the service.\",\n",
    "    \"Customer support was okay, nothing special.\",\n",
    "    \"Amazing experience! Fast delivery and great product.\",\n",
    "    \"Terrible quality, would not recommend.\"\n",
    "]\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "for s in samples:\n",
    "    print(s, \"â†’\", predict_sentiment(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1du0T4i4cpA"
   },
   "source": [
    "####  CARDIFF NLP SENTIMENT MODEL - twitter-roberta-base-sentiment-latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tZhOsCx30ww",
    "outputId": "b187caa7-9d3d-4df3-e637-3d255082291b"
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 1. INSTALLS\n",
    "# ---------------------------------------------\n",
    "!pip install -q transformers torch langdetect pandas scikit-learn nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "from langdetect import detect, DetectorFactory\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2. SETUP\n",
    "# ---------------------------------------------\n",
    "nltk.download(\"stopwords\")\n",
    "DetectorFactory.seed = 0\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "stop_words = set(stopwords.words(\"english\")) - {\"no\", \"nor\", \"not\"}\n",
    "\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3. CLEANING\n",
    "# ---------------------------------------------\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text): return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    tokens = [w for w in text.split() if w not in stop_words]\n",
    "    return \" \".join(tokens) if tokens else \"neutral\"\n",
    "\n",
    "def is_english(text):\n",
    "    try: return detect(text) == \"en\"\n",
    "    except: return False\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 4. LOAD DATA\n",
    "# ---------------------------------------------\n",
    "df = pd.read_csv(\"/content/chatgpt_style_reviews_dataset.csv\")\n",
    "df = df.dropna(subset=[\"review\", \"rating\"])\n",
    "df = df[df[\"review\"].apply(is_english)]\n",
    "df[\"cleaned\"] = df[\"review\"].apply(clean_text)\n",
    "\n",
    "def label_sentiment(r):\n",
    "    r = int(r)\n",
    "    if r >= 4: return \"Positive\"\n",
    "    elif r == 3: return \"Neutral\"\n",
    "    else: return \"Negative\"\n",
    "\n",
    "df[\"sentiment\"] = df[\"rating\"].apply(label_sentiment)\n",
    "df = df[[\"cleaned\", \"sentiment\"]]\n",
    "\n",
    "print(\"\\nOriginal distribution:\\n\", df[\"sentiment\"].value_counts())\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5. BALANCE CLASSES (UPSAMPLING)\n",
    "# ---------------------------------------------\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df.sentiment==\"Negative\"]\n",
    "df_minority_pos = df[df.sentiment==\"Positive\"]\n",
    "df_minority_neu = df[df.sentiment==\"Neutral\"]\n",
    "\n",
    "df_pos_upsampled = resample(df_minority_pos, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "df_neu_upsampled = resample(df_minority_neu, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([df_majority, df_pos_upsampled, df_neu_upsampled])\n",
    "print(\"\\nBalanced distribution:\\n\", df_balanced[\"sentiment\"].value_counts())\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 6. SPLIT\n",
    "# ---------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced[\"cleaned\"], df_balanced[\"sentiment\"],\n",
    "    test_size=0.2, stratify=df_balanced[\"sentiment\"], random_state=42\n",
    ")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 7. LOAD SENTIMENT MODEL\n",
    "# ---------------------------------------------\n",
    "print(\"\\nLoading sentiment model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\").to(device)\n",
    "\n",
    "labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "\n",
    "def predict_sentiment(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    probs = softmax(outputs.logits, dim=-1)\n",
    "    preds = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "    return [labels[p] for p in preds]\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 8. EVALUATION\n",
    "# ---------------------------------------------\n",
    "y_pred = predict_sentiment(X_test.tolist())\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=labels))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 9. TEST SAMPLES\n",
    "# ---------------------------------------------\n",
    "samples = [\n",
    "    \"The product quality is excellent but delivery was slow.\",\n",
    "    \"I am not happy with the service.\",\n",
    "    \"Customer support was okay, nothing special.\",\n",
    "    \"Amazing experience! Fast delivery and great product.\",\n",
    "    \"Good but expensive.\",\n",
    "    \"Itâ€™s okay, nothing special.\",\n",
    "    \"Terrible quality, would not recommend.\",\n",
    "    \"The chatbot helps a lot with my assignments, love it!\"\n",
    "]\n",
    "\n",
    "sample_pred = predict_sentiment(samples)\n",
    "\n",
    "print(\"\\nSample Predictions:\\n\")\n",
    "for s, p in zip(samples, sample_pred):\n",
    "    print(f\"{s}\\nâ†’ {p}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOTpuAXlZhfN"
   },
   "source": [
    "### Roberta model and Hybrid rule engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jByz38KY-72h",
    "outputId": "41a1b31d-3a7d-4893-c073-a9554b51138a"
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 1. INSTALLS\n",
    "# ---------------------------------------------\n",
    "!pip install -q transformers torch langdetect pandas scikit-learn nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "from langdetect import detect, DetectorFactory\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report,\n",
    "    confusion_matrix, f1_score, roc_auc_score\n",
    ")\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2. SETUP\n",
    "# ---------------------------------------------\n",
    "nltk.download(\"stopwords\")\n",
    "DetectorFactory.seed = 0\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "stop_words = set(stopwords.words(\"english\")) - {\"no\", \"nor\", \"not\"}\n",
    "\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3. CLEANING\n",
    "# ---------------------------------------------\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    tokens = [w for w in text.split() if w not in stop_words]\n",
    "    return \" \".join(tokens) if tokens else \"neutral\"\n",
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 4. LOAD DATA\n",
    "# ---------------------------------------------\n",
    "df = pd.read_csv(\"/content/chatgpt_style_reviews_dataset.csv\")\n",
    "df = df.dropna(subset=[\"review\", \"rating\"])\n",
    "df = df[df[\"review\"].apply(is_english)]\n",
    "df[\"cleaned\"] = df[\"review\"].apply(clean_text)\n",
    "\n",
    "def label_sentiment(r):\n",
    "    r = int(r)\n",
    "    if r >= 4: return \"Positive\"\n",
    "    if r == 3: return \"Neutral\"\n",
    "    return \"Negative\"\n",
    "\n",
    "df[\"sentiment\"] = df[\"rating\"].apply(label_sentiment)\n",
    "df = df[[\"cleaned\", \"sentiment\"]]\n",
    "\n",
    "print(\"\\nOriginal distribution:\\n\", df[\"sentiment\"].value_counts())\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5. BALANCE CLASSES\n",
    "# ---------------------------------------------\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_neg = df[df.sentiment == \"Negative\"]\n",
    "df_pos = df[df.sentiment == \"Positive\"]\n",
    "df_neu = df[df.sentiment == \"Neutral\"]\n",
    "\n",
    "max_n = max(len(df_neg), len(df_pos), len(df_neu))\n",
    "\n",
    "df_neg_up = resample(df_neg, replace=True, n_samples=max_n, random_state=42)\n",
    "df_pos_up = resample(df_pos, replace=True, n_samples=max_n, random_state=42)\n",
    "df_neu_up = resample(df_neu, replace=True, n_samples=max_n, random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([df_neg_up, df_pos_up, df_neu_up]).sample(frac=1)\n",
    "\n",
    "print(\"\\nBalanced distribution:\\n\", df_balanced[\"sentiment\"].value_counts())\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 6. SPLIT\n",
    "# ---------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced[\"cleaned\"],\n",
    "    df_balanced[\"sentiment\"],\n",
    "    test_size=0.2,\n",
    "    stratify=df_balanced[\"sentiment\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 7. LOAD ROBERTA MODEL\n",
    "# ---------------------------------------------\n",
    "print(\"\\nLoading sentiment model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    ").to(device)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 8. PREDICT FUNCTIONS\n",
    "# ---------------------------------------------\n",
    "def model_probs(text):\n",
    "    enc = tokenizer([text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "    probs = softmax(logits, dim=-1).cpu().numpy()[0]\n",
    "    return probs\n",
    "\n",
    "\n",
    "def hybrid_predict(texts, neutral_thresh=0.48):\n",
    "    results = []\n",
    "\n",
    "    neg_kw = [\"terrible\", \"awful\", \"worst\", \"bad\", \"poor\", \"hate\"]\n",
    "    pos_kw = [\"excellent\", \"amazing\", \"great\", \"love\", \"fantastic\", \"awesome\"]\n",
    "    neg_phrases = [\"not good\", \"not happy\", \"not satisfied\", \"not recommend\"]\n",
    "    pos_phrases = [\"very good\", \"really good\", \"highly recommend\"]\n",
    "\n",
    "    for t in texts:\n",
    "        txt = t.lower()\n",
    "        probs = model_probs(t)\n",
    "        pred = labels[np.argmax(probs)]\n",
    "        conf = probs.max()\n",
    "\n",
    "        # phrase overrides\n",
    "        if any(p in txt for p in neg_phrases):\n",
    "            results.append(\"Negative\"); continue\n",
    "        if any(p in txt for p in pos_phrases):\n",
    "            results.append(\"Positive\"); continue\n",
    "\n",
    "        # keyword overrides (no contradiction)\n",
    "        if pred != \"Positive\" and any(k in txt for k in neg_kw):\n",
    "            results.append(\"Negative\"); continue\n",
    "        if pred != \"Negative\" and any(k in txt for k in pos_kw):\n",
    "            results.append(\"Positive\"); continue\n",
    "\n",
    "        # mixed sentiment â†’ neutral\n",
    "        if any(k in txt for k in pos_kw) and any(k in txt for k in neg_kw):\n",
    "            results.append(\"Neutral\"); continue\n",
    "\n",
    "        # low confidence â†’ neutral\n",
    "        if conf < neutral_thresh:\n",
    "            results.append(\"Neutral\"); continue\n",
    "\n",
    "        results.append(pred)\n",
    "\n",
    "    return results\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 9. EVALUATION\n",
    "# ---------------------------------------------\n",
    "print(\"\\n--- Hybrid Model Evaluation ---\")\n",
    "y_pred = hybrid_predict(X_test.tolist())\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "\n",
    "# AUC-ROC\n",
    "y_true_ids = y_test.map({\"Negative\":0, \"Neutral\":1, \"Positive\":2}).values\n",
    "y_probs = np.array([model_probs(t) for t in X_test.tolist()])\n",
    "\n",
    "auc = roc_auc_score(\n",
    "    pd.get_dummies(y_true_ids),\n",
    "    y_probs,\n",
    "    multi_class=\"ovr\",\n",
    "    average=\"macro\"\n",
    ")\n",
    "print(\"Macro AUC-ROC:\", auc)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=labels, zero_division=0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 11. SAMPLE TESTS\n",
    "# ---------------------------------------------\n",
    "samples = [\n",
    "    \"The chatbot helps a lot with my assignments, love it!\",\n",
    "     \"I am not happy with the service.\",\n",
    "    \"Customer support was okay, nothing special.\",\n",
    "     \"Good but expensive.\",\n",
    "    \"Itâ€™s okay, nothing special.\",\n",
    "    \"Terrible quality, would not recommend.\"\n",
    "\n",
    "]\n",
    "\n",
    "print(\"\\nHybrid Predictions:\")\n",
    "for s in samples:\n",
    "    print(f\"{s} â†’ {hybrid_predict([s])[0]}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 10. SAVE MODEL\n",
    "# ---------------------------------------------\n",
    "SAVE_DIR = \"/content/sentiment_analysis_model\"\n",
    "model.save_pretrained(SAVE_DIR)\n",
    "tokenizer.save_pretrained(SAVE_DIR)\n",
    "print(f\"\\nModel + tokenizer saved to {SAVE_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_DCjQ5ZYvtM"
   },
   "source": [
    "### SBERT model, Logistic Regression and Hybrid rule engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "72513a571f004857a42ccdaa4b0fecf8",
      "788ee1c9875e4c2bba68950e12e4f4a7",
      "ccbea04bccd3406daa02403c86427ae0",
      "8553f6e19e764b998b78fcd8507ab631",
      "c377c8ff601d440ab6213e9ac3942c77",
      "7f4e6ba8a45b4cc3a789218c6effa55f",
      "f5c70ebd754e45be9c120d6555d84bec",
      "eff2a05b69a7452a9715ca18a455d7d3",
      "18ae7635803c49c9b905bc28b55075ff",
      "23aaa01380954b86b335fd1838a6baf6",
      "c82cc5b62895454da8a88d11df9fdd85",
      "de425601156c49b7bc2c62630e6b4492",
      "17bddceec3ce44e7a60959131c85442b",
      "76e5a598de1e4828acc21fa0effab550",
      "5f6bdd06b27e4eec83f6047f3b875102",
      "6fc4958ca4cf4619ae2e10260a0db943",
      "54f4c480b7fb4399b8fc6dc0f29984e0",
      "00c1ebe57efd4d9184c9e0befcad5a13",
      "5ee8da3049ac4390a663a2a57e9fcc7c",
      "2ffc3507e1de4c11b11217febb49a06d",
      "a9f023cbafcc4556a48e6215447e2b18",
      "7ce58e43d8384a1ea1cb5ba75d8daa7c"
     ]
    },
    "id": "5zyuG-IShn7m",
    "outputId": "c21561e9-3713-47e2-da28-33f0ac3d511b"
   },
   "outputs": [],
   "source": [
    "###fully corrected - MiniLM + SBERT + Logistic Regression\n",
    "!pip install nltk matplotlib seaborn langdetect imbalanced-learn  nlpaug  transformers\n",
    "!pip install sentence-transformers wordcloud\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "#  IMPORTS\n",
    "# ===============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from langdetect import detect\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# ===============================================================\n",
    "# REQUIRED FUNCTIONS\n",
    "# ===============================================================\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    words = [lemmatizer.lemmatize(w) for w in text.split() if w not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# ===============================================================\n",
    "#  LOAD YOUR DATA\n",
    "# ===============================================================\n",
    "DATA_PATH = \"/content/chatgpt_style_reviews_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df.dropna(subset=[\"review\", \"rating\"])\n",
    "df = df[df[\"review\"].apply(is_english)].reset_index(drop=True)\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"review\"].apply(clean_text)\n",
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].astype(str).str.strip()\n",
    "df = df[df[\"cleaned_text\"].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "# Create sentiment from rating if missing\n",
    "if \"sentiment\" not in df.columns:\n",
    "    def rating_to_sentiment(r):\n",
    "        try:\n",
    "            r = float(r)\n",
    "        except:\n",
    "            return None\n",
    "        if r >= 4:\n",
    "            return \"Positive\"\n",
    "        elif r == 3:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Negative\"\n",
    "    df[\"sentiment\"] = df[\"rating\"].apply(rating_to_sentiment)\n",
    "\n",
    "df = df.dropna(subset=[\"sentiment\"]).reset_index(drop=True)\n",
    "print(\"Original distribution:\\n\", df[\"sentiment\"].value_counts(), \"\\n\")\n",
    "\n",
    "# ------------------------------------------\n",
    "#  AUGMENTATION (Safe Contextual + SBERT)\n",
    "# ------------------------------------------\n",
    "aug1 = naw.ContextualWordEmbsAug(\n",
    "    model_path=\"bert-base-uncased\",\n",
    "    action=\"substitute\",\n",
    "    aug_p=0.25\n",
    ")\n",
    "\n",
    "aug2 = naw.ContextualWordEmbsAug(\n",
    "    model_path=\"bert-base-uncased\",\n",
    "    action=\"insert\",\n",
    "    aug_p=0.15\n",
    ")\n",
    "\n",
    "para_aug = naw.SynonymAug(\n",
    "    model_path=\"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "aug_texts, aug_labels = [], []\n",
    "\n",
    "def to_clean_string(x):\n",
    "    \"\"\"Convert any augmentation output into a valid cleaned string\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        x = \" \".join(map(str, x))\n",
    "    if not isinstance(x, str):\n",
    "        return \"\"\n",
    "    return x.strip()\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    text = row[\"cleaned_text\"]\n",
    "    label = row[\"sentiment\"]\n",
    "    for augmenter in [aug1, aug2, para_aug]:\n",
    "        try:\n",
    "            out = augmenter.augment(text)\n",
    "            clean_out = to_clean_string(out)\n",
    "            if clean_out and len(clean_out) > 3:\n",
    "                aug_texts.append(clean_out)\n",
    "                aug_labels.append(label)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "aug_df = pd.DataFrame({\"cleaned_text\": aug_texts, \"sentiment\": aug_labels})\n",
    "df_final = pd.concat([df, aug_df], ignore_index=True)\n",
    "\n",
    "df_final[\"cleaned_text\"] = df_final[\"cleaned_text\"].astype(str).str.strip()\n",
    "df_final = df_final[df_final[\"cleaned_text\"].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "print(\"\\nFinal counts after augmentation:\\n\")\n",
    "print(df_final[\"sentiment\"].value_counts())\n",
    "\n",
    "# ===============================================================\n",
    "#  LABEL ENCODING\n",
    "# ===============================================================\n",
    "le = LabelEncoder()\n",
    "df_final[\"label\"] = le.fit_transform(df_final[\"sentiment\"])\n",
    "print(\"\\nLabel mapping:\", dict(zip(le.transform(le.classes_), le.classes_)))\n",
    "\n",
    "# ===============================================================\n",
    "#  TRAIN/TEST SPLIT\n",
    "# ===============================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_final[\"cleaned_text\"], df_final[\"label\"],\n",
    "    test_size=0.2, stratify=df_final[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "# ===============================================================\n",
    "#  EMBEDDINGS (MiniLM)\n",
    "# ===============================================================\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "X_train_vec = embedder.encode(X_train.tolist(), convert_to_numpy=True, show_progress_bar=True)\n",
    "X_test_vec = embedder.encode(X_test.tolist(), convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "# ===============================================================\n",
    "#  CLASSIFIER + CALIBRATION\n",
    "# ===============================================================\n",
    "clf = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "calibrated_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "calibrated_clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# ===============================================================\n",
    "#  EVALUATION\n",
    "# ===============================================================\n",
    "preds = calibrated_clf.predict(X_test_vec)\n",
    "probs = calibrated_clf.predict_proba(X_test_vec)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\",\n",
    "      classification_report(y_test, preds, target_names=le.classes_))\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Accuracy: {accuracy_score(y_test, preds)*100:.2f}%\")\n",
    "print(\"Macro F1:\", f1_score(y_test, preds, average=\"macro\"))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, probs, multi_class=\"ovr\"))\n",
    "\n",
    "# ===============================================================\n",
    "#  HYBRID NEUTRAL-SAFE DECISION ENGINE (REVISED)\n",
    "# ===============================================================\n",
    "PROBA_UNCERTAIN = 0.50          # below this, call Neutral\n",
    "NEU_MARGIN = 0.20               # |neg - pos| closeness for Neutral\n",
    "NEU_MIN = 0.15                  # minimal neutral proba to allow Neutral\n",
    "NEU_TOP_GAP = 0.10              # if Neutral is close to max, call Neutral\n",
    "\n",
    "NEUTRAL_CUES = {\n",
    "    \"not sure\", \"unsure\", \"mixed\", \"ambivalent\", \"meh\", \"okay\", \"ok\",\n",
    "    \"just okay\", \"fine\", \"average\", \"so so\", \"so-so\", \"decent\",\n",
    "    \"i don't love it\", \"i dont love it\", \"i don't hate it\", \"i dont hate it\",\n",
    "    \"it is just okay\", \"itâ€™s just okay\", \"it is okay\", \"itâ€™s okay\"\n",
    "}\n",
    "POSITIVE_CUES = {\n",
    "    \"fantastic\", \"great\", \"excellent\", \"amazing\", \"love\", \"wonderful\",\n",
    "    \"awesome\", \"superb\", \"terrific\", \"good\"\n",
    "}\n",
    "NEGATIVE_CUES = {\n",
    "    \"disappointed\", \"bad\", \"terrible\", \"awful\", \"hate\", \"poor\", \"worse\",\n",
    "    \"not good\", \"mediocre\", \"buggy\"\n",
    "}\n",
    "\n",
    "def _has_cue(text, cues):\n",
    "    t = text.lower()\n",
    "    return any(c in t for c in cues)\n",
    "\n",
    "def hybrid_predict(text, debug=False):\n",
    "    cleaned = clean_text(text)\n",
    "    vec = embedder.encode([cleaned], convert_to_numpy=True)\n",
    "    proba = calibrated_clf.predict_proba(vec)[0]\n",
    "\n",
    "    proba_dict = dict(zip(le.classes_, proba))\n",
    "    neg_p = proba_dict.get(\"Negative\", 0.0)\n",
    "    neu_p = proba_dict.get(\"Neutral\", 0.0)\n",
    "    pos_p = proba_dict.get(\"Positive\", 0.0)\n",
    "\n",
    "    max_p = max(proba)\n",
    "    pred_idx = np.argmax(proba)\n",
    "    pred_label = le.inverse_transform([pred_idx])[0]\n",
    "\n",
    "    # 1) Strong lexical cues override probabilities\n",
    "    if _has_cue(text, POSITIVE_CUES) and not _has_cue(text, NEGATIVE_CUES):\n",
    "        return \"Positive\"\n",
    "    if _has_cue(text, NEGATIVE_CUES) and not _has_cue(text, POSITIVE_CUES):\n",
    "        return \"Negative\"\n",
    "    # Neutral cue wins unless there is a very strong class (>0.65)\n",
    "    if _has_cue(text, NEUTRAL_CUES) and max_p < 0.65:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    # 2) Uncertainty fallback\n",
    "    if max_p < PROBA_UNCERTAIN:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    # 3) Pos-Neg tie â†’ Neutral if Neutral is non-trivial\n",
    "    if abs(neg_p - pos_p) < NEU_MARGIN and neu_p > NEU_MIN:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    # 4) Neutral near top â†’ Neutral\n",
    "    if (max_p - neu_p) < NEU_TOP_GAP and neu_p > NEU_MIN:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Probabilities: {proba_dict}\")\n",
    "    return pred_label\n",
    "\n",
    "# ===============================================================\n",
    "# BATCH PREDICT\n",
    "# ===============================================================\n",
    "def predict_list(samples):\n",
    "    for s in samples:\n",
    "        print(f\"{s} â†’ {hybrid_predict(s, debug=True)}\")\n",
    "\n",
    "# ===============================================================\n",
    "#  TEST\n",
    "# ===============================================================\n",
    "samples = [\n",
    "    \"Amazing service! I will definitely recommend it to others.\",\n",
    "    \"Very disappointed. It didnâ€™t work as expected.\",\n",
    "    \"I don't love it, I don't hate it. It is just okay.\"\n",
    "]\n",
    "predict_list(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NMASWYrhntE",
    "outputId": "a9e43ad4-1574-4ca5-e49c-f57ec36bd9ab"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model_dict = {\n",
    "    \"embedder\": embedder,\n",
    "    \"classifier\": calibrated_clf,\n",
    "    \"label_encoder\": le,\n",
    "    \"hybrid_thresholds\": {\n",
    "        \"PROBA_UNCERTAIN\": PROBA_UNCERTAIN,\n",
    "        \"NEU_MARGIN\": NEU_MARGIN,\n",
    "        \"NEU_MIN\": NEU_MIN,\n",
    "        \"NEU_TOP_GAP\": NEU_TOP_GAP\n",
    "    },\n",
    "    \"neutral_cues\": list(NEUTRAL_CUES),\n",
    "    \"positive_cues\": list(POSITIVE_CUES),\n",
    "    \"negative_cues\": list(NEGATIVE_CUES)\n",
    "}\n",
    "\n",
    "joblib.dump(model_dict, \"sentiment_pipeline.joblib\")\n",
    "\n",
    "print(\"Model saved as sentiment_pipeline.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "oLlv0T85yo9K",
    "outputId": "c176cc10-af07-42f5-d8e9-0c8a78c0ebb0"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"sentiment_pipeline.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-i4DUSIfApiL"
   },
   "source": [
    "## Streamlit UI Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWmndtIKk-7w",
    "outputId": "84821d6d-fdd7-445d-c3d5-d20ae77a1c6c"
   },
   "outputs": [],
   "source": [
    "!pip install streamlit pyngrok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tn181rFGM9a5",
    "outputId": "925bff2e-0794-4e47-8e96-f7dc7b2aec03"
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# SAFE SINGLE-TIME NLTK DOWNLOAD\n",
    "# --------------------------------------------------------\n",
    "def safe_nltk_download(pkg):\n",
    "    try:\n",
    "        nltk.data.find(f\"corpora/{pkg}\")\n",
    "    except LookupError:\n",
    "        nltk.download(pkg)\n",
    "\n",
    "safe_nltk_download(\"stopwords\")\n",
    "safe_nltk_download(\"wordnet\")\n",
    "safe_nltk_download(\"omw-1.4\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# LOAD MODEL PIPELINE\n",
    "# --------------------------------------------------------\n",
    "saved = joblib.load(\"/content/sentiment_pipeline.joblib\")\n",
    "\n",
    "embedder = saved[\"embedder\"]\n",
    "clf = saved[\"classifier\"]\n",
    "label_encoder = saved[\"label_encoder\"]\n",
    "\n",
    "PROBA_UNCERTAIN = saved[\"hybrid_thresholds\"][\"PROBA_UNCERTAIN\"]\n",
    "NEU_MARGIN = saved[\"hybrid_thresholds\"][\"NEU_MARGIN\"]\n",
    "NEU_MIN = saved[\"hybrid_thresholds\"][\"NEU_MIN\"]\n",
    "NEU_TOP_GAP = saved[\"hybrid_thresholds\"][\"NEU_TOP_GAP\"]\n",
    "\n",
    "NEUTRAL_CUES = set(saved[\"neutral_cues\"])\n",
    "POSITIVE_CUES = set(saved[\"positive_cues\"])\n",
    "NEGATIVE_CUES = set(saved[\"negative_cues\"])\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# TEXT CLEANING\n",
    "# --------------------------------------------------------\n",
    "def clean_text(text: str):\n",
    "    text = text.lower()\n",
    "    words = [lemmatizer.lemmatize(w) for w in text.split() if w not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# HYBRID PREDICTION (Rules + ML)\n",
    "# --------------------------------------------------------\n",
    "def hybrid_predict(text):\n",
    "    cleaned = clean_text(text)\n",
    "\n",
    "    # Rule-based cues\n",
    "    if any(word in cleaned for word in POSITIVE_CUES):\n",
    "        return \"Positive\"\n",
    "    if any(word in cleaned for word in NEGATIVE_CUES):\n",
    "        return \"Negative\"\n",
    "    if any(word in cleaned for word in NEUTRAL_CUES):\n",
    "        return \"Neutral\"\n",
    "\n",
    "    # ML Prediction\n",
    "    emb = embedder.encode([cleaned])\n",
    "    proba = clf.predict_proba(emb)[0]\n",
    "    pred_idx = np.argmax(proba)\n",
    "    pred_label = label_encoder.classes_[pred_idx]\n",
    "\n",
    "    if proba[pred_idx] < PROBA_UNCERTAIN:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    if abs(\n",
    "        proba[label_encoder.classes_.tolist().index(\"Positive\")]\n",
    "        - proba[label_encoder.classes_.tolist().index(\"Negative\")]\n",
    "    ) < NEU_MARGIN:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    return pred_label\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# STREAMLIT UI\n",
    "# --------------------------------------------------------\n",
    "st.set_page_config(page_title=\"Hybrid Sentiment Analyzer\", layout=\"wide\")\n",
    "\n",
    "st.sidebar.title(\"ðŸ“Š Menu\")\n",
    "page = st.sidebar.radio(\"Choose an option:\", [\"Home\", \"Single Prediction\", \"Batch Prediction\", \"EDA Analysis\",\"Developer Info\"])\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "#  Home\n",
    "# --------------------------------------------------------\n",
    "if page == \"Home\":\n",
    "    st.header(\"Project Title - AI Echo: Your Smartest Conversational Partner\")\n",
    "    st.subheader(\"Dataset\")\n",
    "    df=pd.read_csv(\"/content/chatgpt_style_reviews_dataset.csv\")\n",
    "    st.dataframe(df)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1ï¸âƒ£ SINGLE PREDICTION\n",
    "# --------------------------------------------------------\n",
    "elif page == \"Single Prediction\":\n",
    "    st.header(\"ðŸ§  Sentiment Analysis\")\n",
    "    st.subheader(\"ðŸ” Single Text Sentiment Prediction\")\n",
    "\n",
    "    text = st.text_area(\"Enter text to analyze:\")\n",
    "\n",
    "    if st.button(\"Predict\"):\n",
    "        if text.strip() == \"\":\n",
    "            st.warning(\"Please enter some text.\")\n",
    "        else:\n",
    "            sentiment = hybrid_predict(text)\n",
    "            st.success(f\"**Prediction: {sentiment}**\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2ï¸âƒ£ BATCH PREDICTION\n",
    "# --------------------------------------------------------\n",
    "elif page == \"Batch Prediction\":\n",
    "    st.subheader(\"ðŸ“ Batch Prediction (Upload CSV)\")\n",
    "\n",
    "    st.info(\"Your CSV must have a text column. Supported names: text, review, comment, message, feedback\")\n",
    "\n",
    "    file = st.file_uploader(\"Upload CSV\", type=[\"csv\"])\n",
    "\n",
    "    if file:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        possible_cols = [\"text\", \"review\", \"comment\", \"message\", \"feedback\"]\n",
    "\n",
    "        text_col = None\n",
    "        for col in df.columns:\n",
    "            if col.lower() in [c.lower() for c in possible_cols]:\n",
    "                text_col = col\n",
    "                break\n",
    "\n",
    "        if text_col is None:\n",
    "            st.error(\"No valid text column found.\")\n",
    "        else:\n",
    "            df[\"Sentiment\"] = df[text_col].astype(str).apply(hybrid_predict)\n",
    "            st.write(df.head())\n",
    "\n",
    "            csv = df.to_csv(index=False).encode(\"utf-8\")\n",
    "            st.download_button(\"Download Predictions\", csv, \"sentiment_predictions.csv\", \"text/csv\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3ï¸âƒ£ EDA ANALYSIS\n",
    "# --------------------------------------------------------\n",
    "elif page == \"EDA Analysis\":\n",
    "\n",
    "    st.subheader(\"ðŸ“ˆ Sentiment EDA & Visualization\")\n",
    "\n",
    "    DATA_PATH = \"/content/chatgpt_style_reviews_dataset.csv\"\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "    # Required columns check\n",
    "    required_cols = [\"review\", \"rating\", \"date\"]\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            st.error(f\"Missing required column: {col}\")\n",
    "            st.stop()\n",
    "\n",
    "    df = df.dropna(subset=[\"review\", \"rating\"])\n",
    "    df[\"sentiment\"] = df[\"rating\"].apply(lambda r: \"Positive\" if r >= 4 else (\"Neutral\" if r == 3 else \"Negative\"))\n",
    "    df[\"cleaned_text\"] = df[\"review\"].astype(str).apply(clean_text)\n",
    "    df[\"review_length\"] = df[\"review\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "    chart_option = st.sidebar.radio(\n",
    "        \"Select Chart\",\n",
    "        [\n",
    "            \"Overall Distribution\",\n",
    "            \"Sentiment vs Rating\",\n",
    "            \"Word Clouds per Sentiment\",\n",
    "            \"Sentiment Over Time\",\n",
    "            \"Verified vs Non-Verified\",\n",
    "            \"Review length vs Sentiment\",\n",
    "            \"Sentiment by Location\",\n",
    "            \"Platform Sentiment\",\n",
    "            \"Sentiment by ChatGptVersion\",\n",
    "            \"Topic Modeling on Negative Reviews\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # ----- 1. Overall Distribution -----\n",
    "    if chart_option == \"Overall Distribution\":\n",
    "        fig, ax = plt.subplots(figsize=(3, 2))\n",
    "        sns.countplot(x=\"sentiment\", data=df, palette=\"magma\", ax=ax)\n",
    "        st.pyplot(fig, use_container_width=False)\n",
    "\n",
    "    # ----- 2. Sentiment vs Rating -----\n",
    "    elif chart_option == \"Sentiment vs Rating\":\n",
    "        sentiment_by_rating = df.groupby(\"rating\")[\"sentiment\"].value_counts(normalize=True).unstack()\n",
    "        fig, ax = plt.subplots(figsize=(3, 2))\n",
    "        sentiment_by_rating.plot(kind=\"bar\", ax=ax)\n",
    "        st.pyplot(fig, use_container_width=False)\n",
    "\n",
    "    # ----- 3. Word Clouds -----\n",
    "    elif chart_option == \"Word Clouds per Sentiment\":\n",
    "        tabs = st.tabs([\"Positive\", \"Neutral\", \"Negative\"])\n",
    "        for sentiment_name, tab in zip([\"Positive\", \"Neutral\", \"Negative\"], tabs):\n",
    "            with tab:\n",
    "                text = \" \".join(df[df[\"sentiment\"] == sentiment_name][\"cleaned_text\"])\n",
    "                wc = WordCloud(width=400, height=200, background_color=\"white\").generate(text)\n",
    "                fig, ax = plt.subplots(figsize=(3, 2))\n",
    "                ax.imshow(wc)\n",
    "                ax.axis(\"off\")\n",
    "                st.pyplot(fig, use_container_width=False)\n",
    "\n",
    "    # ----- 4. Sentiment Over Time -----\n",
    "    elif chart_option == \"Sentiment Over Time\":\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df[\"month\"] = df[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "        trend = df.groupby([\"month\", \"sentiment\"]).size().reset_index(name=\"count\")\n",
    "        pivot = trend.pivot(index=\"month\", columns=\"sentiment\", values=\"count\").fillna(0)\n",
    "\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(3, 2))\n",
    "        pivot.plot(ax=ax)\n",
    "        plt.xticks(rotation=45)\n",
    "        st.pyplot(fig, use_container_width=False)\n",
    "\n",
    "    # ----- 5. Verified vs Non-Verified -----\n",
    "    elif chart_option == \"Verified vs Non-Verified\":\n",
    "        if \"verified_purchase\" not in df.columns:\n",
    "            st.error(\"Dataset missing column: verified_purchase\")\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize=(3, 2))\n",
    "            sns.barplot(x=\"verified_purchase\", y=\"rating\", data=df, estimator=\"mean\", ax=ax)\n",
    "            st.pyplot(fig, use_container_width=False)\n",
    "\n",
    "    # ----- 6. Review Length vs Sentiment -----\n",
    "    elif chart_option == \"Review length vs Sentiment\":\n",
    "        fig, ax = plt.subplots(figsize=(3, 2))\n",
    "        sns.boxplot(x=\"sentiment\", y=\"review_length\", data=df, ax=ax)\n",
    "        st.pyplot(fig, use_container_width=False)\n",
    "\n",
    "    # ----- 7. Sentiment by Location -----\n",
    "    elif chart_option == \"Sentiment by Location\":\n",
    "        if \"location\" not in df.columns:\n",
    "            st.error(\"Dataset missing column: location\")\n",
    "        else:\n",
    "            loc_sent = df.groupby(\"location\")[\"rating\"].mean().sort_values(ascending=False).head(10)\n",
    "            fig, ax = plt.subplots(figsize=(3, 2))\n",
    "            loc_sent.plot(kind=\"bar\", ax=ax)\n",
    "            st.pyplot(fig, use_container_width=False)\n",
    "\n",
    "    # ----- 8. Platform Sentiment -----\n",
    "    elif chart_option == \"Platform Sentiment\":\n",
    "        if \"platform\" not in df.columns:\n",
    "            st.error(\"Dataset missing column: platform\")\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize=(3, 2))\n",
    "            sns.barplot(x=\"platform\", y=\"rating\", data=df, estimator=\"mean\", ax=ax)\n",
    "            st.pyplot(fig, use_container_width=False)\n",
    "\n",
    "    # ----- 9. ChatGPT Version -----\n",
    "    elif chart_option == \"Sentiment by ChatGptVersion\":\n",
    "        if \"version\" not in df.columns:\n",
    "            st.error(\"Dataset missing column: version\")\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize=(3, 2))\n",
    "            sns.countplot(x=\"version\", hue=\"sentiment\", data=df, ax=ax)\n",
    "            plt.xticks(rotation=45)\n",
    "            st.pyplot(fig, use_container_width=False)\n",
    "\n",
    "    # ----- 10. Topic Modeling -----\n",
    "    elif chart_option == \"Topic Modeling on Negative Reviews\":\n",
    "        neg_text = \" \".join(df[df[\"sentiment\"] == \"Negative\"][\"cleaned_text\"])\n",
    "        wc = WordCloud(width=600, height=300, background_color=\"white\", colormap=\"Reds\").generate(neg_text)\n",
    "        fig, ax = plt.subplots(figsize=(3, 2))\n",
    "        ax.imshow(wc)\n",
    "        ax.axis(\"off\")\n",
    "        st.pyplot(fig, use_container_width=False)\n",
    "\n",
    "#--------------------------------------\n",
    "   #   Developer Info\n",
    "#-------------------------------------------------\n",
    "elif page == \"Developer Info\":\n",
    "    st.header(\"Developer Info\")\n",
    "    st.markdown(\"\"\"\n",
    "    **Developed by:** T RENUGADEVI\n",
    "\n",
    "    **Course:** Data Science\n",
    "    **Skills:** Python, Pandas, NLP, Machine Learning, Deep Learning, NLTK, Scikit-Learn, Matplotlib, Seaborn, Streamlit\"\"\", True)\n",
    "\n",
    "    st.snow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uALA0Q1VM_j3",
    "outputId": "e345b877-5ce9-4486-af5d-b7552443830c"
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyngrok import ngrok\n",
    "ngrok.set_auth_token(\"30u56xSW1OXarvhpphlGjOLDba5_4XNvBZtLaNP4vsMfENoex\")\n",
    "\n",
    "# Kill any existing tunnels\n",
    "ngrok.kill()\n",
    "\n",
    "# Start Streamlit\n",
    "get_ipython().system_raw('streamlit run app.py --server.port 8501 &')\n",
    "\n",
    "# Open a tunnel on port 8501\n",
    "public_url = ngrok.connect(8501)\n",
    "print(\"ðŸ‘‰ Your app is live here:\", public_url)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00c1ebe57efd4d9184c9e0befcad5a13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "179743e0505c4ce4960fed08b934de5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17bddceec3ce44e7a60959131c85442b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54f4c480b7fb4399b8fc6dc0f29984e0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_00c1ebe57efd4d9184c9e0befcad5a13",
      "value": "Batches:â€‡100%"
     }
    },
    "17bf4f4902014d6f82b843b2d768e2a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b80392e46a8e4c1a8c4d1b35af37ef55",
       "IPY_MODEL_656cf2efac1746ce9ad43a31ba92e13a",
       "IPY_MODEL_8254aff29a5941e4afe5c03c40359910"
      ],
      "layout": "IPY_MODEL_84c5ba7e79ec45bea2e98d110a5870b5"
     }
    },
    "18ae7635803c49c9b905bc28b55075ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "19b29bf8f4fe405d99928fc146d76d65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23aaa01380954b86b335fd1838a6baf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27de81ab823e423db2161728dc726504": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29b93cec6b8a4b7db9a78520b65210de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ffc3507e1de4c11b11217febb49a06d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "38fbdaef740c443b9d0e44b5cd7a28dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3cc9f1141ede4b3fb61fd011be77f346": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e6af79d0151420191a6600939758b18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fc068577d2347de92cb17d8a3d6e20e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54f4c480b7fb4399b8fc6dc0f29984e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5621abb68d2d41fa87591b6619a99d10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c487d0d73516425ca796aff3da93a5f8",
       "IPY_MODEL_5c115e418ccf402ba9dd71bde6253b42",
       "IPY_MODEL_8abac191fbe94752a8451277682b43b0"
      ],
      "layout": "IPY_MODEL_a8c81171dd124fc6a3dd67abc2c7a684"
     }
    },
    "5c115e418ccf402ba9dd71bde6253b42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a010830bb2444477bc3d4ed132699da8",
      "max": 12,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9d2c94f9253b4ce5b381ff446e7d8a14",
      "value": 12
     }
    },
    "5e7e8c8202264e9dafb19a5389631dce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ee8da3049ac4390a663a2a57e9fcc7c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f6bdd06b27e4eec83f6047f3b875102": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9f023cbafcc4556a48e6215447e2b18",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7ce58e43d8384a1ea1cb5ba75d8daa7c",
      "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡30.91it/s]"
     }
    },
    "6168b7d5086f45ec8b97098d8c996db1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f15588376af24b86bbe817657c83a6aa",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c840e68d754b4b3db0c4acf8a90114d7",
      "value": "Map:â€‡100%"
     }
    },
    "656cf2efac1746ce9ad43a31ba92e13a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9c9ca43fac449eba54ee281dbc04071",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aa98452321724fb893233a40ac3545ac",
      "value": 1
     }
    },
    "6fc4958ca4cf4619ae2e10260a0db943": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72513a571f004857a42ccdaa4b0fecf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_788ee1c9875e4c2bba68950e12e4f4a7",
       "IPY_MODEL_ccbea04bccd3406daa02403c86427ae0",
       "IPY_MODEL_8553f6e19e764b998b78fcd8507ab631"
      ],
      "layout": "IPY_MODEL_c377c8ff601d440ab6213e9ac3942c77"
     }
    },
    "76e5a598de1e4828acc21fa0effab550": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ee8da3049ac4390a663a2a57e9fcc7c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2ffc3507e1de4c11b11217febb49a06d",
      "value": 1
     }
    },
    "788ee1c9875e4c2bba68950e12e4f4a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f4e6ba8a45b4cc3a789218c6effa55f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f5c70ebd754e45be9c120d6555d84bec",
      "value": "Batches:â€‡100%"
     }
    },
    "7ce58e43d8384a1ea1cb5ba75d8daa7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f4e6ba8a45b4cc3a789218c6effa55f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8254aff29a5941e4afe5c03c40359910": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29b93cec6b8a4b7db9a78520b65210de",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3fc068577d2347de92cb17d8a3d6e20e",
      "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡21.15it/s]"
     }
    },
    "827bec617723437799184f13dbe0c436": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4fe33548c58486684dc7756f3ab7949",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f7e6e1088939466a89914e496e603f42",
      "value": 48
     }
    },
    "84c5ba7e79ec45bea2e98d110a5870b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8553f6e19e764b998b78fcd8507ab631": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23aaa01380954b86b335fd1838a6baf6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c82cc5b62895454da8a88d11df9fdd85",
      "value": "â€‡4/4â€‡[00:00&lt;00:00,â€‡63.58it/s]"
     }
    },
    "8abac191fbe94752a8451277682b43b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90986c630a2a469c92b48f6dbc60a82a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5e7e8c8202264e9dafb19a5389631dce",
      "value": "â€‡12/12â€‡[00:00&lt;00:00,â€‡141.15â€‡examples/s]"
     }
    },
    "90986c630a2a469c92b48f6dbc60a82a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99d548631bf447a9afb38dbdc7eee3fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19b29bf8f4fe405d99928fc146d76d65",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fe0f850a2f8841459bb3093cde483696",
      "value": "â€‡48/48â€‡[00:00&lt;00:00,â€‡419.87â€‡examples/s]"
     }
    },
    "9d2c94f9253b4ce5b381ff446e7d8a14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a010830bb2444477bc3d4ed132699da8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4fe33548c58486684dc7756f3ab7949": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8c81171dd124fc6a3dd67abc2c7a684": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9c9ca43fac449eba54ee281dbc04071": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9f023cbafcc4556a48e6215447e2b18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa98452321724fb893233a40ac3545ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b80392e46a8e4c1a8c4d1b35af37ef55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27de81ab823e423db2161728dc726504",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_38fbdaef740c443b9d0e44b5cd7a28dc",
      "value": "Batches:â€‡100%"
     }
    },
    "c377c8ff601d440ab6213e9ac3942c77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c487d0d73516425ca796aff3da93a5f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e6af79d0151420191a6600939758b18",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3cc9f1141ede4b3fb61fd011be77f346",
      "value": "Map:â€‡100%"
     }
    },
    "c82cc5b62895454da8a88d11df9fdd85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c840e68d754b4b3db0c4acf8a90114d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ccbea04bccd3406daa02403c86427ae0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eff2a05b69a7452a9715ca18a455d7d3",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_18ae7635803c49c9b905bc28b55075ff",
      "value": 4
     }
    },
    "dae2d2b579fa424d8a7dfb2aba583b00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6168b7d5086f45ec8b97098d8c996db1",
       "IPY_MODEL_827bec617723437799184f13dbe0c436",
       "IPY_MODEL_99d548631bf447a9afb38dbdc7eee3fe"
      ],
      "layout": "IPY_MODEL_179743e0505c4ce4960fed08b934de5c"
     }
    },
    "de425601156c49b7bc2c62630e6b4492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17bddceec3ce44e7a60959131c85442b",
       "IPY_MODEL_76e5a598de1e4828acc21fa0effab550",
       "IPY_MODEL_5f6bdd06b27e4eec83f6047f3b875102"
      ],
      "layout": "IPY_MODEL_6fc4958ca4cf4619ae2e10260a0db943"
     }
    },
    "eff2a05b69a7452a9715ca18a455d7d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f15588376af24b86bbe817657c83a6aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5c70ebd754e45be9c120d6555d84bec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7e6e1088939466a89914e496e603f42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe0f850a2f8841459bb3093cde483696": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
